{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Reinforcement Learning Course - Project\n",
    "Group Members: Iulia-Elena Teodorescu, Konstantinos Tantoulas, Likhith Bedara Agrahara Venkateshamurthy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create grid environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid dimensions\n",
    "n_rows = 11\n",
    "n_cols = 11\n",
    "actions = ['up', 'down', 'left', 'right']\n",
    "\n",
    "# Initialize Q-values\n",
    "q_matrix = np.zeros((n_rows, n_cols, 4))\n",
    "\n",
    "# Define rewards\n",
    "reward_matrix = np.full((n_rows, n_cols), -100.)\n",
    "\n",
    "# Define open areas\n",
    "open_areas = {1: list(range(1, 10)), 2: [1, 7, 9], 3: list(range(1, 10)),\n",
    "              4: [3, 7], 5: list(range(1, 10)), 6: [1,3,4,5,9], 7: [1,3,4,5,6,7,8,9],\n",
    "              8: [1,3, 7,9], 9: [1,2,3,4,5,6,7,9]}\n",
    "\n",
    "# Set up reward values for different types of locations\n",
    "DEPOSIT_REWARD = 100\n",
    "CHARGING_REWARD = -5\n",
    "OPEN_AREA_REWARD = -1\n",
    "COLLISION_PENALTY = -50\n",
    "\n",
    "# Assign rewards to cells\n",
    "def assign_rewards():\n",
    "    # Assign open area rewards\n",
    "    for row in range(1, 10):\n",
    "        for col in open_areas[row]:\n",
    "            reward_matrix[row, col] = OPEN_AREA_REWARD\n",
    "    \n",
    "    # Assign deposit station rewards\n",
    "    deposit_stations = [(0, 5), (5, 0), (10, 5)]\n",
    "    for row, col in deposit_stations:\n",
    "        reward_matrix[row, col] = DEPOSIT_REWARD\n",
    "    \n",
    "    # Assign charging station rewards\n",
    "    charging_stations = [(1, 1), (5, 1), (9, 9)]\n",
    "    for row, col in charging_stations:\n",
    "        reward_matrix[row, col] = CHARGING_REWARD\n",
    "\n",
    "# Set up the reward matrix\n",
    "assign_rewards()\n",
    "\n",
    "# Check if state is terminal\n",
    "def is_terminal_state(row, col):\n",
    "    return reward_matrix[row, col] != -1.\n",
    "\n",
    "# Get a random starting position\n",
    "def random_start(occupied_positions=None):\n",
    "    if occupied_positions is None:\n",
    "        occupied_positions = set()\n",
    "    valid_positions = [(r, c) for r, cols in open_areas.items() for c in cols if (r, c) not in occupied_positions]\n",
    "    return valid_positions[np.random.randint(len(valid_positions))]\n",
    "\n",
    "# Assign unique tasks to robots, ensuring tasks are not in occupied positions\n",
    "def assign_tasks_to_robots(num_robots, occupied_positions):\n",
    "    tasks = []\n",
    "    while len(tasks) < num_robots:\n",
    "        task = random_start(occupied_positions)\n",
    "        if task not in tasks:\n",
    "            tasks.append(task)\n",
    "    return tasks\n",
    "\n",
    "# Calculate Manhattan distance\n",
    "def calculate_manhattan_distance(pos1, pos2):\n",
    "    return abs(pos1[0] - pos2[0]) + abs(pos1[1] - pos2[1])\n",
    "\n",
    "# Find the closest charging station\n",
    "def find_closest_charging_station(robot_position, charging_stations):\n",
    "    min_distance = float('inf')\n",
    "    closest_station = None\n",
    "    for station in charging_stations:\n",
    "        distance = calculate_manhattan_distance(robot_position, station)\n",
    "        if distance < min_distance:\n",
    "            min_distance = distance\n",
    "            closest_station = station\n",
    "    return closest_station\n",
    "\n",
    "# Select action using epsilon-greedy strategy\n",
    "def select_action(row, col, epsilon_value):\n",
    "    if np.random.random() < epsilon_value:\n",
    "        return np.random.randint(4)\n",
    "    return np.argmax(q_matrix[row, col])\n",
    "\n",
    "# Calculate next position\n",
    "def calculate_next_position(row, col, action):\n",
    "    if actions[action] == 'up' and row > 0:\n",
    "        row -= 1\n",
    "    elif actions[action] == 'right' and col < n_cols - 1:\n",
    "        col += 1\n",
    "    elif actions[action] == 'down' and row < n_rows - 1:\n",
    "        row += 1\n",
    "    elif actions[action] == 'left' and col > 0:\n",
    "        col -= 1\n",
    "    return row, col\n",
    "\n",
    "# Check if a position is occupied\n",
    "def is_position_occupied(pos, occupied_positions):\n",
    "    return pos in occupied_positions\n",
    "\n",
    "# Retry logic for collision handling\n",
    "def retry_action(row, col, epsilon_value, occupied_positions, retries=3):\n",
    "    for _ in range(retries):\n",
    "        action = select_action(row, col, epsilon_value)\n",
    "        next_row, next_col = calculate_next_position(row, col, action)\n",
    "        if not is_position_occupied((next_row, next_col), occupied_positions):\n",
    "            return next_row, next_col, action\n",
    "    return row, col, -1  # Return original position and invalid action if all retries fail\n",
    "\n",
    "# Move dynamically toward charging station\n",
    "def move_toward_charger(row, col, target_row, target_col):\n",
    "    if row < target_row:\n",
    "        return row + 1, col\n",
    "    elif row > target_row:\n",
    "        return row - 1, col\n",
    "    elif col < target_col:\n",
    "        return row, col + 1\n",
    "    elif col > target_col:\n",
    "        return row, col - 1\n",
    "    return row, col\n",
    "\n",
    "def calculate_priority(robot, task_position, max_energy=100):\n",
    "    distance = calculate_manhattan_distance(robot['position'], task_position)\n",
    "    priority_score = (robot['energy'] / max_energy) * (1 / (distance + 1))  # Avoid division by zero\n",
    "    return priority_score\n",
    "\n",
    "def avoid_congestion(row, col, occupied_positions):\n",
    "    for action in range(4):  # Try all actions\n",
    "        next_row, next_col = calculate_next_position(row, col, action)\n",
    "        if not is_position_occupied((next_row, next_col), occupied_positions):\n",
    "            return next_row, next_col\n",
    "    return row, col  # Stay in place if no congestion-free path is found\n",
    "\n",
    "def check_congestion(occupied_positions, position, radius=1, congestion_threshold=2):\n",
    "    \"\"\"\n",
    "    Check if the given position is in a high-congestion area.\n",
    "\n",
    "    Args:\n",
    "        occupied_positions (set): Set of all occupied positions (tuples of (row, col)).\n",
    "        position (tuple): The position to check (row, col).\n",
    "        radius (int): The radius to define the neighborhood around the position.\n",
    "        congestion_threshold (int): The number of robots that constitute congestion.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if the position is congested, False otherwise.\n",
    "    \"\"\"\n",
    "    row, col = position\n",
    "    congestion_count = 0\n",
    "\n",
    "    # Check all positions within the radius\n",
    "    for r in range(row - radius, row + radius + 1):\n",
    "        for c in range(col - radius, col + radius + 1):\n",
    "            if (r, c) in occupied_positions:\n",
    "                congestion_count += 1\n",
    "                if congestion_count >= congestion_threshold:\n",
    "                    return True  # Congestion detected\n",
    "\n",
    "    return False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training parameters\n",
    "epsilon = 1.0\n",
    "gamma = 0.9\n",
    "alpha = 0.9\n",
    "max_steps = 100\n",
    "episodes = 1000\n",
    "num_robots = 2\n",
    "initial_energy = 100\n",
    "energy_cost = 1\n",
    "low_energy_threshold = 10  # Guide robots to charging stations before they run out of energy\n",
    "rewards = []\n",
    "\n",
    "# Training\n",
    "for episode in range(episodes):\n",
    "    # Initialize robots and tasks\n",
    "    occupied_positions = set()\n",
    "    robots = [{'position': random_start(occupied_positions), 'energy': initial_energy, 'has_package': False} for _ in range(num_robots)]\n",
    "    for robot in robots:\n",
    "        occupied_positions.add(robot['position'])\n",
    "    tasks = assign_tasks_to_robots(num_robots, occupied_positions)\n",
    "\n",
    "    total_reward = 0\n",
    "    for step in range(max_steps):\n",
    "        step_occupied_positions = set()\n",
    "\n",
    "        # Priority-Based Task Reallocation\n",
    "        task_priority = []\n",
    "        for i, robot in enumerate(robots):\n",
    "            if not robot['has_package']:\n",
    "                # Calculate priority scores for each task\n",
    "                task_priority.append({\n",
    "                    'robot': i,\n",
    "                    'task': tasks[i],\n",
    "                    'priority': calculate_priority(robot, tasks[i])\n",
    "                })\n",
    "\n",
    "        # Sort robots by priority to decide task assignments dynamically\n",
    "        task_priority.sort(key=lambda x: x['priority'], reverse=True)\n",
    "        task_assignments = {item['robot']: item['task'] for item in task_priority}\n",
    "\n",
    "        for i, robot in enumerate(robots):\n",
    "            row, col = robot['position']\n",
    "            reward = 0\n",
    "\n",
    "            # Energy depletion handling\n",
    "            if robot['energy'] <= low_energy_threshold:\n",
    "                charging_station = find_closest_charging_station((row, col), charging_stations)\n",
    "                next_row, next_col = move_toward_charger(row, col, *charging_station)\n",
    "                reward += CHARGING_REWARD\n",
    "                if (next_row, next_col) == charging_station:\n",
    "                    robot['energy'] = initial_energy\n",
    "            else:\n",
    "                # Select action and calculate next position\n",
    "                action = select_action(row, col, epsilon)\n",
    "                next_row, next_col = calculate_next_position(row, col, action)\n",
    "\n",
    "                # Advanced Collision Avoidance\n",
    "                if is_position_occupied((next_row, next_col), step_occupied_positions):\n",
    "                    # Check congestion and retry\n",
    "                    if check_congestion(occupied_positions, (next_row, next_col)):\n",
    "                        next_row, next_col = avoid_congestion(row, col, occupied_positions)\n",
    "                    else:\n",
    "                        next_row, next_col, action = retry_action(row, col, epsilon, step_occupied_positions)\n",
    "                        if action == -1:\n",
    "                            reward += COLLISION_PENALTY  # Penalize if no valid retry is possible\n",
    "\n",
    "                # Task completion or deposit handling\n",
    "                if (next_row, next_col) == task_assignments[i] and not robot['has_package']:\n",
    "                    robot['has_package'] = True\n",
    "                    reward += DEPOSIT_REWARD\n",
    "                elif robot['has_package'] and (next_row, next_col) in deposit_stations:\n",
    "                    robot['has_package'] = False  # Deliver package\n",
    "                    reward += DEPOSIT_REWARD\n",
    "                else:\n",
    "                    reward = reward_matrix[next_row, next_col]\n",
    "\n",
    "                # Update energy\n",
    "                robot['energy'] -= energy_cost\n",
    "\n",
    "            # Update Q-value\n",
    "            q_current = q_matrix[row, col, action]\n",
    "            td_error = reward + gamma * np.max(q_matrix[next_row, next_col]) - q_current\n",
    "            q_matrix[row, col, action] = q_current + alpha * td_error\n",
    "\n",
    "            # Update robot's position\n",
    "            robot['position'] = (next_row, next_col)\n",
    "            step_occupied_positions.add(robot['position'])\n",
    "\n",
    "            total_reward += reward\n",
    "\n",
    "        # Decay epsilon\n",
    "        epsilon = max(0.01, epsilon * 0.995)\n",
    "\n",
    "    # Record total reward for the episode\n",
    "    rewards.append(total_reward)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lunar",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
